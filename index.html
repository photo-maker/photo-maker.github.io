<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>PhotoMaker</title>
<link href="./files/style.css" rel="stylesheet">
<link href="./files/button.css" rel="stylesheet">
<link href="./files/slider.css" rel="stylesheet">

<link rel="apple-touch-icon" sizes="180x180" href="assets/logo-180x180.png">
<link rel="icon" type="image/png" sizes="32x32" href="assets/logo-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="assets/logo-16x16.png">
<script type="text/javascript" src="./files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./files/jquery.js"></script>
<script src="./files/util.js" content="text/javascript"></script>
<link rel="manifest" href="/site.webmanifest">
<!-- <script src="util.js" content="text/javascript"></script> -->


</head>

<body>
<div class="content">
  <div class="logo" style="text-align: center;">
    <a href="index.html">
      <img src="./assets/logo.png">
    </a>
  </div>
  <h1><strong>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</strong></h1>
  <p id="authors"><a href="https://paper99.github.io/">Zhen Li</a	><sup>1,2*</sup> <a href="https://github.com/ljzycmd">Mingdeng Cao</a><sup>2,3*</sup> <a href="https://xinntao.github.io/">Xintao Wang</a><sup>2&#x2709;</sup> <a href="https://scholar.google.com/citations?user=zJvrrusAAAAJ&hl=en/">Zhongang Qi</a><sup>2</sup> <a href="https://mmcheng.net/cmm/">Ming-Ming Cheng</a><sup>1&#x2709;</sup> <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en/">Ying Shan</a><sup>2</sup><br>
    <br>
  <span style="font-size: 18px"><sup>1</sup>Nankai University &nbsp;&nbsp;&nbsp;&nbsp; <sup>2</sup>ARC Lab, Tencent PCG &nbsp;&nbsp;&nbsp;&nbsp; <sup>3</sup>University of Tokyo
  </span></p>
  <div style="text-align: center;">
    <span style="font-size: 14px"><sup>*</sup> Interns in ARC Lab, Tencent PCG  &nbsp;&nbsp;&nbsp;&nbsp;  &#x2709; Corresponding Authors</span>
  </div>
  <div style="text-align: center;">
    <video width=80% autoplay muted loop controls>
      <source src="assets\photomaker_demo.mp4" type="video/mp4">
    </video>
    <br>
    Note: The prompt displayed in the video is a simplified version.
  </div>
  <h3 style="text-align:center"><em>Let us create photos/paintings/avatars for <span style="color:rgb(253, 60, 94);">anyone</span> in <span style="color:rgb(241, 73, 177);">any style</span> <span style="color:rgb(84, 151, 233);">within seconds</span>.</em></h3>    <font size="+2">
          <p style="text-align: center;">
            <a href="https://huggingface.co/papers/2312.04461" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/TencentARC/PhotoMaker" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://huggingface.co/spaces/TencentARC/PhotoMaker" target="_blank">[Demo]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://huggingface.co/TencentARC/PhotoMaker" target="_blank">[Model Card]</a> &nbsp;&nbsp;&nbsp;&nbsp;
	    <!-- (<font color="#C70039">new!</font>) <a href="https://github.com/TencentARC/PhotoMaker" target="_blank">[Dataset]</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
            <a href="files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
    </font>
    <p style="text-align: center;"> 
      <!-- We are currently organizing the code and demo to ensure that everyone can enjoy the wonderful journey that PhotoMaker may bring as soon as possible.
      If you want to support and cheer for us, please star our project. ^_^ -->
    </p>
  </div>

  <div class="content">
  <h2 style="text-align:center;">Latest Examples</h2>
  <h3>Realistic photos</h3>
  Select to browse the personalization results. The first row is the reference ID image.
    <div class="realContainer">
      <div class="real1stCol"><img class="realImage" src="./assets/inputs/lecun.jpg"></div>
      <div class="real2ndCol"><img class="realImage" src="./assets/inputs/scarlett.jpg"></div>
      <div class="real3rdCol"><img class="realImage" src="./assets/inputs/qianxi.jpg"></div>
      <div class="real4thCol"><img class="realImage" src="./assets/inputs/yangmi.jpg"></div>
      <div class="real5thCol"><img class="realImage" src="./assets/inputs/lenna.png"></div>
      <div class="real6thCol"><img class="realImage" src="./assets/inputs/newton.jpg"></div>
      <div class="realResult"><img class="resultImage" src="./assets/results_real/real1stCol.jpg"></div>
    </div>
  <h3>Stylization</h3>
  Select to browse the personalization results. The first row is the reference ID image.
    <div class="artContainer">
      <div class="art1stCol"><img class="artImage" src="./assets/inputs/lecun.jpg"></div>
      <div class="art2ndCol"><img class="artImage" src="./assets/inputs/scarlett.jpg"></div>
      <div class="art3rdCol"><img class="artImage" src="./assets/inputs/qianxi.jpg"></div>
      <div class="art4thCol"><img class="artImage" src="./assets/inputs/yangmi.jpg"></div>
      <div class="art5thCol"><img class="artImage" src="./assets/inputs/lenna.png"></div>
      <div class="art6thCol"><img class="artImage" src="./assets/inputs/ez.jpg"></div>
      <div class="artResult"><img class="resultImage" src="./assets/results_art/art1stCol.jpg"></div>
    </div>

</div>

<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts. 
    However, existing personalized generation methods cannot simultaneously satisfy the requirements of high efficiency, promising identity (ID) fidelity, and flexible text controllability.
    In this work, we introduce <strong>PhotoMaker</strong>, an efficient personalized text-to-image generation method, which mainly encodes an arbitrary number of input ID images into a stack ID embedding for preserving ID information.
    Such an embedding, serving as a unified ID representation, can not only encapsulate the characteristics of the same input ID comprehensively, but also accommodate the characteristics of different IDs for subsequent integration.
    This paves the way for more intriguing and practically valuable applications.
    Besides, to drive the training of our PhotoMaker, we propose an ID-oriented data construction pipeline to assemble the training data.
    Under the nourishment of the dataset constructed through the proposed pipeline,
    our PhotoMaker demonstrates better ID preservation ability than test-time fine-tuning based methods, yet provides significant speed improvements, high-quality generation results, strong generalization capabilities, and a wide range of applications.
  </p>
</div>
<!-- <div class="content">
  <h2>Background</h2>
  <p> Given a particular subject such as clock (shown in the real images on the left), it is very challenging to generate it in different contexts with state-of-the-art text-to-image models, while maintaining high fidelity to its key visual features. Even with dozens of iterations over a text prompt that contains a detailed description of the appearance of the clock (<em>"retro style yellow alarm clock with a white clock face and a yellow number three on the right part of the clock face in the jungle"</em>), the Imagen model [Saharia et al., 2022] can't reconstruct its key visual features (third column). Furthermore, even models whose text embedding lies in a shared language-vision space and can create semantic variations of the image, such as DALL-E2 [Ramesh et al., 2022], can neither reconstruct the appearance of the given subject nor modify the context (second column). In contrast, our approach (right) can synthesize the clock with high fidelity and in new contexts (<em>"a [V] clock in the jungle"</em>).</p>
  <br>
  <img class="summary-img" src="./assets/background.png" style="width:100%;"> <br>
</div> -->
<div class="content">
  <h2 style="text-align:center;">Method</h2>
  <p> Our method transforms a few input images of the same identity into a stacked ID embedding.
    This embedding can be regarded as a unified representation of the ID to be generated.
    During the inference stage, the images constituting the stacked ID embedding can originate from different IDs.
    We then can synthesize the customized ID in difference contexts.
  <br>
  <img class="summary-img" src="./assets/framework.jpg" style="width:80%;"> <br>
  <p>We first obtain the text embedding and image embeddings from text encoder(s) and image encoder, respectively.
    Then, we extract the fused embedding by merging the corresponding class embedding (e.g., man and woman) and each image embedding.
    Next, we concatenate all fused embeddings along the length dimension to form the <strong>stacked ID embedding</strong>.
    Finally, we feed the stacked ID embedding to all cross-attention layers for adaptively merging the ID content in the diffusion model.
  Note that although we use images of the same ID with the masked background during training, we can directly input images of different IDs without background distortion to create a new ID during inference.</p>
  <p>
    We leave the discussions about ID-oriented data construction pipeline in our paper.
  </p>
  <br>
</div>
<div class="content">
  <h2>Recontextualization</h2>
  <p>We demonstrate the generation capabilities of our PhotoMaker under basic prompts. 
    We display the conditioning prompts below each image.
  </p>
  <img class="summary-img" src="./assets/website_recontext.jpg" style="width:100%;">
  <!-- <img class="summary-img" src="./assets/results.png" style="width:100%;"> -->
</div>

<div class="content">
  <h2>Bringing a person in artwork/old photo into reality</h2>
  <p>By
    taking artistic paintings, sculptures, or old photos of a person
    as input, our PhotoMaker can bring a person from the last century or even ancient times to the present century to
    “take” photos for them. We display the conditioning prompts below each image. </p>
  <img class="summary-img" src="./assets/website_oldphoto.jpg" style="width:100%;">
  <!-- <img class="summary-img" src="./assets/results.png" style="width:100%;"> -->
</div>

<div class="content">
  <h2>Stylization</h2>
  <p>Our PhotoMaker not only possesses the capability to generate realistic
    human photos, but it also allows for stylization while
    preserving ID attributes. We display the conditioning prompts at the first row.</p>
  <img class="summary-img" src="./assets/stylization.jpg" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Changing Age or Gender</h2>
  <p>By simply replacing class words (e.g., man and woman), our method can achieve changes
    in gender and age while maintaining the original identity.</p>
  <img class="summary-img" src="./assets/change_age_gender.jpg" style="width:100%;">
  <!-- <img class="summary-img" src="./assets/results.png" style="width:100%;"> -->
</div>


<div class="content">
  <h2>Identity Mixing</h2>
  <p>If the users provide images of different
    IDs as input, our PhotoMaker can well integrate the characteristics
    of different IDs to form a new ID.</p>
  <img class="summary-img" src="./assets/identity_mixing.jpg" style="width:100%;"> <br>
  <br>
  <p>For identity mixing, our method can adjust the merge ratio by either
  controlling the percentage of identity images within the input
  image pool or through the method of prompt weighting.</p>
  <p>We first show that how our method
  customizes a new ID by controlling the proportion of different
  IDs in the input image pool.</p>
  <img class="summary-img" src="./assets/change_mix_ratio_image.jpg" style="width:100%;"> <br>
  <p>We then multiply the embedding corresponding to the images
    related to a specific ID by a coefficient to control its proportion
    of integration into the new ID.</p>
  <img class="summary-img" src="./assets/change_mix_ratio_embed.jpg" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Comparisons</h2>
  <p>
    Compared to other methods, our PhotoMaker can simultaneously satisfy high-quality and diverse
    generation capabilities, promising editability, high inference efficiency, and strong ID fidelity.
    More comparison results can be found in our paper.
    We display the conditioning prompts at the second column.
  </p>
  <br>
  <img class="summary-img" src="./assets/comparison_recontext.jpg" style="width:100%;"> <br>
</div>
<!-- <div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects (animals, objects) in different contexts. While general text-to-image models might be biased towards specific attributes when synthesizing images from text, our approach enables the user to get a better reconstruction of their desirable subjects. On contrary, malicious parties might try to use such images to mislead viewers. This is a common issue, existing in other generative models approaches or content manipulation techniques. Future research in generative modeling, and specifically of personalized generative priors, must continue investigating and revalidating these concerns.</p>
  <br>
</div> -->
<div class="content">
  <h2>BibTex</h2>
  <code> @inproceedings{li2023photomaker,<br>
  &nbsp;&nbsp;title={PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding},<br>
  &nbsp;&nbsp;author={Li, Zhen and Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Cheng, Ming-Ming and Shan, Ying},<br>
  &nbsp;&nbsp;booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>
  &nbsp;&nbsp;year={2024}<br>
  } </code> 
</div>
<div class="content" id="acknowledgements">
  <p>
    <!-- <strong>Acknowledgements</strong>: -->
    <!-- If you want an image removed from this page or have other requests, please contact us at <a href="mailto:zhenli1031@gmail.com">zhenli1031@gmail.com</a>. -->
    <!-- <br> -->
    Our project page is borrowed from <a href="https://dreambooth.github.io/">DreamBooth</a>.
    <!-- Recycling a familiar <a href="https://chail.github.io/latent-composition/">template</a> ;). --> 
  </p>
</div>
<script content="text/javascript">initArtSelection(); </script>
<script content="text/javascript">initRealSelection(); </script>

</body>
</html>
